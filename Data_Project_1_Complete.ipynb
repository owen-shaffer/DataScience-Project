{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCXBrRK0X826i3b4z/8IB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owen-shaffer/DataScience-Project/blob/main/Data_Project_1_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/owen-shaffer/DataScience-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yc5_l_Bbb7G",
        "outputId": "a33d5499-4a86-4e12-a206-bc2bc9b07746"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DataScience-Project'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 59 (delta 23), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (59/59), 2.45 MiB | 2.98 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF7h8jGIYIO6",
        "outputId": "7cdeaf84-b598-47b9-e267-5a2f984c90f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide the path for your data: /content/DataScience-Project/SanFranPlastic.csv\n",
            "\n",
            " Data Summary\n",
            "Number of rows: 44226\n",
            "Number of columns: 8\n",
            "\n",
            "This is the first 5 rows of the data\n",
            "  SampleMatrix              SampleID                           PlasticType  \\\n",
            "0        manta  CB-4-Manta-21Aug2017  Polyethylene/polypropylene copolymer   \n",
            "1        manta  CB-4-Manta-21Aug2017                             Polyester   \n",
            "2        manta  CB-4-Manta-21Aug2017  Polyethylene/polypropylene copolymer   \n",
            "3        manta  CB-4-Manta-21Aug2017                             Polyester   \n",
            "4        manta  CB-4-Manta-21Aug2017                             Polyester   \n",
            "\n",
            "  MorphologicalCategory       Color  Length.mm  Width.mm  \\\n",
            "0                 Fiber  Light Blue      2.427     0.037   \n",
            "1                 Fiber       Black      4.385     0.040   \n",
            "2                 Fiber       Clear      2.907     0.080   \n",
            "3                 Fiber  Light Blue      1.869     0.035   \n",
            "4                 Fiber       Black      3.112     0.035   \n",
            "\n",
            "                                 MatrixName  \n",
            "0  samplewater, particulate, >125 to 355 um  \n",
            "1  samplewater, particulate, >125 to 355 um  \n",
            "2  samplewater, particulate, >125 to 355 um  \n",
            "3  samplewater, particulate, >125 to 355 um  \n",
            "4  samplewater, particulate, >125 to 355 um  \n",
            "\n",
            "\n",
            "Would you like to remove any columns? (y/n) y\n",
            "What range of columns would you like to remove? \n",
            "Beginning at column: 4\n",
            "Ending at column: 6\n",
            "  SampleMatrix              SampleID                           PlasticType  \\\n",
            "0        manta  CB-4-Manta-21Aug2017  Polyethylene/polypropylene copolymer   \n",
            "1        manta  CB-4-Manta-21Aug2017                             Polyester   \n",
            "2        manta  CB-4-Manta-21Aug2017  Polyethylene/polypropylene copolymer   \n",
            "3        manta  CB-4-Manta-21Aug2017                             Polyester   \n",
            "4        manta  CB-4-Manta-21Aug2017                             Polyester   \n",
            "\n",
            "  MorphologicalCategory  Width.mm                                MatrixName  \n",
            "0                 Fiber     0.037  samplewater, particulate, >125 to 355 um  \n",
            "1                 Fiber     0.040  samplewater, particulate, >125 to 355 um  \n",
            "2                 Fiber     0.080  samplewater, particulate, >125 to 355 um  \n",
            "3                 Fiber     0.035  samplewater, particulate, >125 to 355 um  \n",
            "4                 Fiber     0.035  samplewater, particulate, >125 to 355 um  \n",
            "\n",
            "\n",
            "Columns removed\n",
            "\n",
            "\n",
            "Would you like to convert your data to csv (1), json(2), or sql (3)? 3\n",
            "What would you like to name your file? plasticsf\n",
            "\n",
            "Is your file a csv (1) or json (2)? 1\n",
            "What is the name of your new database? plasticsf\n",
            "What is the name of your new table? plastics\n",
            "\n",
            " Data Summary\n",
            "Number of rows: 44226\n",
            "Number of columns: 6\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pandas import json_normalize\n",
        "import csv\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "#Functions\n",
        "#These functions mostly take in two parameters, the data file and a name for the converted data file. The function opens the file and reads it into a\n",
        "#pandas dataframe. From there the data can be saved into the desired format.\n",
        "#When converting into an sql database table, the name of the new table is also a parameter\n",
        "\n",
        "def convert_csv_to_json(csv_file, json_file):\n",
        "    with open(csv_file, 'r') as s:\n",
        "      df = pd.read_csv(s)\n",
        "      df.to_json(json_file, orient='records')#This line and following similiar lines convert the data frame to desired file type\n",
        "\n",
        "def convert_json_to_csv(json_file, csv_file):\n",
        "  with open(data, 'r') as s:\n",
        "    json_data = json.load(s)\n",
        "    df = pd.json_normalize(json_data) # Within json data sometimes there are lists within dictionaries or vice versa. Pandas does not like turning this into a df so it needs to be 'flattened'. The normalize function converts this nested data into rows and columns\n",
        "    df.to_csv(csv_file)\n",
        "\n",
        "def convert_csv_to_sql(csv_file, sql_file, table):\n",
        "    with open(csv_file, 'r') as s:\n",
        "      df = pd.read_csv(s)\n",
        "      df.to_sql(table, con=sqlite3.connect(sql_file))#Writes data to a table in a sql database\n",
        "\n",
        "def convert_json_to_sql(json_file, sql_file,table):\n",
        "    with open(json_file, 'r') as s:\n",
        "      json_data = json.load(s)\n",
        "      df = pd.json_normalize(json_data)\n",
        "      for col in df.columns: #This code accounts for lists and dictioneries in the json data by turning them into strings. Without it the data cant be converted into a .db because sql only accepts basic text, int, float, null.\n",
        "      #The code iterates over each column and checks its type if it is an object so a list or dictionary then it goes through the conversion.\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = df[col].apply(lambda x: json.dumps(x) if isinstance(x, (dict, list)) else x)\n",
        "      df.to_sql(table, con=sqlite3.connect(sql_file), index=False)\n",
        "\n",
        "def convert_sql_to_csv(sql_file, table, new_file, new_file_type):\n",
        "  conn = sqlite3.connect(sql_file) #Connects to the database\n",
        "  df = pd.read_sql(\"SELECT * FROM \"+table, conn) #Gets the data from given table in the database\n",
        "  df.to_csv(new_file)\n",
        "\n",
        "def convert_sql_to_json(sql_file, table, new_file):\n",
        "  conn = sqlite3.connect(sql_file) #Connects to the database\n",
        "  df = pd.read_sql(\"SELECT * FROM \"+table, conn) #Gets the data from given table in the database\n",
        "  df.to_json(new_file)\n",
        "\n",
        "#This function takes in a dataframe and prints the number of rows and columns by taking the values from the .shape function output\n",
        "def summarize_data(df):\n",
        "    print(\"\\n Data Summary\")\n",
        "    print(f\"Number of rows: {df.shape[0]}\")\n",
        "    print(f\"Number of columns: {df.shape[1]}\")\n",
        "\n",
        "\n",
        "\n",
        "# #Data ingesting and converting\n",
        "\n",
        "data = input(\"Provide the path for your data: \")\n",
        "\n",
        "# #This chunk opens the data based on file type and turns it into a datafram\n",
        "if '.json' in data:\n",
        "  with open(data, 'r') as f:\n",
        "    json_data = json.load(f)\n",
        "    df = pd.json_normalize(json_data)# Within json data sometimes there are lists within dictionaries or vice versa. Pandas does not like turning this into a df so it needs to be 'flattened'. The normalize function converts this nested data into rows and columns\n",
        "if '.csv' in data:\n",
        "  df = pd.read_csv(data)\n",
        "if '.db' in data:\n",
        "  conn = sqlite3.connect(data)\n",
        "  table = input(\"What is the name of the desired table? \")\n",
        "  query = \"SELECT * FROM \" + table\n",
        "  data = pd.read_sql(query, conn)\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "summarize_data(df)\n",
        "\n",
        "print('')\n",
        "print('This is the first 5 rows of the data')\n",
        "print(df.head(), flush=True)\n",
        "\n",
        "print('')\n",
        "print('')\n",
        "\n",
        "remove = input(\"Would you like to remove any columns? (y/n) \")\n",
        "if remove == 'y':\n",
        "  print(\"What range of columns would you like to remove? \")\n",
        "  start_column = input(\"Beginning at column: \")\n",
        "  end_column = input(\"Ending at column: \")\n",
        "  print('')\n",
        "  if int(start_column) > int(end_column): #Range would not work if x was greater than y\n",
        "    print(\"Invalid range\")\n",
        "  else:\n",
        "    df = df.drop(df.columns[int(start_column):int(end_column)], axis=1) #Removes columns based on the range given\n",
        "    print(df.head())\n",
        "    print('')\n",
        "    print('')\n",
        "  if int(start_column)>len(df.columns): #This accounts for the numbers provided being outside the number of columns\n",
        "    print(\"Invalid range\")\n",
        "  else:\n",
        "    print(\"Columns removed\")\n",
        "else:\n",
        "  print(\"No columns removed\")\n",
        "\n",
        "print('')\n",
        "print('')\n",
        "choice = input(\"Would you like to convert your data to csv (1), json(2), or sql (3)? \")\n",
        "name = input(\"What would you like to name your file? \")\n",
        "print('')\n",
        "\n",
        "# #This section uses the functions previously defined to convert data into different formats given the users inputs\n",
        "if choice == '1':\n",
        "  if '.csv' in data:\n",
        "    print(\"Your file is already in csv format\")\n",
        "  else:\n",
        "    if '.json' in data:\n",
        "      convert_json_to_csv(data, name + '.csv')\n",
        "    if '.db' in data:\n",
        "      convert_sql_to_csv(data, table, name + '.csv')\n",
        "\n",
        "if choice == '2':\n",
        "  if '.json' in data:\n",
        "    print(\"Your file is already in json format\")\n",
        "  else:\n",
        "    if '.db' in data:\n",
        "      convert_sql_to_json(data, table, name + '.json')\n",
        "    if '.csv' in data:\n",
        "      convert_csv_to_json(data, name + '.json')\n",
        "\n",
        "if choice == '3':\n",
        "  file_type = input(\"Is your file a csv (1) or json (2)? \")\n",
        "  if file_type == '1':\n",
        "    database_path = input(\"What is the name of your new database? \") + \".db\"\n",
        "    table = input(\"What is the name of your new table? \")\n",
        "    convert_csv_to_sql(data, database_path, table)\n",
        "  if file_type == '2':\n",
        "    database_path = input(\"What is the name of your new database? \")+\".db\"\n",
        "    table = input(\"What is the name of your new table? \")\n",
        "    convert_json_to_sql(data, database_path, table)\n",
        "\n",
        "summarize_data(df)"
      ]
    }
  ]
}