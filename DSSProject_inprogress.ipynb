{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2fA5xCPXovAePkAafcetO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owen-shaffer/DataScience-Project/blob/main/DSSProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/owen-shaffer/DataScience-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yc5_l_Bbb7G",
        "outputId": "a17cb86e-cb30-4f28-8273-d719dd385790"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DataScience-Project'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 50 (delta 18), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (50/50), 2.44 MiB | 2.39 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF7h8jGIYIO6",
        "outputId": "7a8d3972-14d3-4f00-bba6-3a79632f47fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide the path for your data: /content/plastictest.db\n",
            "What is the name of your table? plastictest\n",
            "\n",
            " Data Summary\n",
            "Number of rows: 44226\n",
            "Number of columns: 9\n",
            "\n",
            "This is the first 5 rows of the data\n",
            "   index SampleMatrix              SampleID  \\\n",
            "0      0        manta  CB-4-Manta-21Aug2017   \n",
            "1      1        manta  CB-4-Manta-21Aug2017   \n",
            "2      2        manta  CB-4-Manta-21Aug2017   \n",
            "3      3        manta  CB-4-Manta-21Aug2017   \n",
            "4      4        manta  CB-4-Manta-21Aug2017   \n",
            "\n",
            "                            PlasticType MorphologicalCategory       Color  \\\n",
            "0  Polyethylene/polypropylene copolymer                 Fiber  Light Blue   \n",
            "1                             Polyester                 Fiber       Black   \n",
            "2  Polyethylene/polypropylene copolymer                 Fiber       Clear   \n",
            "3                             Polyester                 Fiber  Light Blue   \n",
            "4                             Polyester                 Fiber       Black   \n",
            "\n",
            "   Length.mm  Width.mm                                MatrixName  \n",
            "0      2.427     0.037  samplewater, particulate, >125 to 355 um  \n",
            "1      4.385     0.040  samplewater, particulate, >125 to 355 um  \n",
            "2      2.907     0.080  samplewater, particulate, >125 to 355 um  \n",
            "3      1.869     0.035  samplewater, particulate, >125 to 355 um  \n",
            "4      3.112     0.035  samplewater, particulate, >125 to 355 um  \n",
            "\n",
            "\n",
            "Would you like to remove any columns? (y/n) n\n",
            "No columns removed\n",
            "\n",
            "\n",
            "Would you like to convert your data to csv (1), json(2), or sql (3)? 2\n",
            "What would you like to name your file? plastictestconversion\n",
            "\n",
            "\n",
            " Data Summary\n",
            "Number of rows: 44226\n",
            "Number of columns: 9\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pandas import json_normalize\n",
        "import csv\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "#Functions\n",
        "#These functions mostly take in two parameters, the data file and a name for the converted data file. The function opens the file and reads it into a\n",
        "#pandas dataframe. From there the data can be saved into the desired format.\n",
        "#When converting into an sql database table, the name of the new table is also a parameter\n",
        "\n",
        "def convert_csv_to_json(csv_file, json_file):\n",
        "    with open(csv_file, 'r') as s:\n",
        "      df = pd.read_csv(s)\n",
        "      df.to_json(json_file, orient='records')\n",
        "\n",
        "def convert_json_to_csv(json_file, csv_file):\n",
        "  with open(data, 'r') as s:\n",
        "    json_data = json.load(s)\n",
        "    df = pd.json_normalize(json_data) # Within json data sometimes there are lists within dictionaries or vice versa. Pandas does not like turning this into a df so it needs to be 'flattened'. The normalize function converts this nested data into rows and columns\n",
        "    df.to_csv(csv_file)\n",
        "\n",
        "def convert_csv_to_sql(csv_file, sql_file, table):\n",
        "    with open(csv_file, 'r') as s:\n",
        "      df = pd.read_csv(s)\n",
        "      df.to_sql(table, con=sqlite3.connect(sql_file))#Writes data to a table in a sql database\n",
        "\n",
        "def convert_json_to_sql(json_file, sql_file,table):\n",
        "    with open(json_file, 'r') as s:\n",
        "      json_data = json.load(s)\n",
        "      df = pd.json_normalize(json_data)\n",
        "      for col in df.columns: #This code accounts for lists and dictioneries in the json data by turning them into strings. Without it the data cant be converted into a .db because sql only accepts basic text, int, float, null.\n",
        "      #The code iterates over each column and checks its type if it is an object so a list or dictionary then it goes through the conversion.\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = df[col].apply(lambda x: json.dumps(x) if isinstance(x, (dict, list)) else x)\n",
        "      df.to_sql(table, con=sqlite3.connect(sql_file), index=False)\n",
        "\n",
        "def convert_sql(sql_file, table, new_file):\n",
        "  conn = sqlite3.connect(sql_file) #Connects to the database\n",
        "  df = pd.read_sql(\"SELECT * FROM\"+table, conn) #Gets the data from given table in the database\n",
        "  input = input(\"Would you like to convert your data to csv (1) or json(2)\")\n",
        "  if input == '1':\n",
        "    df.to_csv(new_file)\n",
        "  elif input == '2':\n",
        "    df.to_json(new_file)\n",
        "  else:\n",
        "    print(\"Invalid input\")\n",
        "\n",
        "#This function takes in a dataframe and prints the number of rows and columns by taking the values from the .shape function output\n",
        "def summarize_data(df):\n",
        "    print(\"\\n Data Summary\")\n",
        "    print(f\"Number of rows: {df.shape[0]}\")\n",
        "    print(f\"Number of columns: {df.shape[1]}\")\n",
        "\n",
        "\n",
        "\n",
        "#Data ingesting and converting\n",
        "\n",
        "data = input(\"Provide the path for your data: \")\n",
        "\n",
        "#This chunk opens the data based on file type and turns it into a datafram\n",
        "if '.json' in data:\n",
        "  with open(data, 'r') as f:\n",
        "    json_data = json.load(f)\n",
        "    df = pd.json_normalize(json_data)# Within json data sometimes there are lists within dictionaries or vice versa. Pandas does not like turning this into a df so it needs to be 'flattened'. The normalize function converts this nested data into rows and columns\n",
        "if '.csv' in data:\n",
        "  df = pd.read_csv(data)\n",
        "if '.db' in data:\n",
        "  conn = sqlite3.connect(data)\n",
        "  table = input(\"What is the name of your table? \")\n",
        "  query = \"SELECT * FROM \" + table\n",
        "  data = pd.read_sql(query, conn)\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "summarize_data(df)\n",
        "\n",
        "print('')\n",
        "print('This is the first 5 rows of the data')\n",
        "print(df.head(), flush=True)\n",
        "\n",
        "print('')\n",
        "print('')\n",
        "\n",
        "remove = input(\"Would you like to remove any columns? (y/n) \")\n",
        "if remove == 'y':\n",
        "  print(\"What range of columns would you like to remove? \")\n",
        "  x_columns = input(\"Beginning at column: \")\n",
        "  y_columns = input(\"Ending at column: \")\n",
        "  if int(x_columns) > int(y_columns): #Range would not work if x was greater than y\n",
        "    print(\"Invalid range\")\n",
        "  else:\n",
        "    df = df.drop(df.columns[int(x_columns):int(y_columns)], axis=1) #Removes columns based on the range given\n",
        "    print(df.head())\n",
        "    print('')\n",
        "    print('')\n",
        "  if int(x_columns)>len(df.columns): #This accounts for the numbers provided being outside the number of columns\n",
        "    print(\"Invalid range\")\n",
        "  else:\n",
        "    print(\"Columns removed\")\n",
        "else:\n",
        "  print(\"No columns removed\")\n",
        "\n",
        "print('')\n",
        "print('')\n",
        "choice = input(\"Would you like to convert your data to csv (1), json(2), or sql (3)? \")\n",
        "name = input(\"What would you like to name your file? \")\n",
        "print('')\n",
        "\n",
        "#This section uses the functions previously defined to convert data into different formats given the users inputs\n",
        "if choice == '1':\n",
        "  if '.csv' in data:\n",
        "    print(\"Your file is already in csv format\")\n",
        "  else:\n",
        "    if '.json' in data:\n",
        "      convert_json_to_csv(data, name + '.csv')\n",
        "    if '.db' in data:\n",
        "      convert_sql(data, name + '.csv')\n",
        "\n",
        "if choice == '2':\n",
        "  if '.json' in data:\n",
        "    print(\"Your file is already in json format\")\n",
        "  else:\n",
        "    if '.db' in data:\n",
        "      convert_sql(data, name + '.json')\n",
        "    if '.csv' in data:\n",
        "      convert_csv_to_json(data, name + '.json')\n",
        "\n",
        "if choice == '3':\n",
        "  file_type = input(\"Is your file a csv (1) or json (2)? \")\n",
        "  if file_type == '1':\n",
        "    database_path = input(\"What is the path to your database? \")\n",
        "    table = input(\"What is the name of your table? \")\n",
        "    convert_csv_to_sql(data, database_path, table)\n",
        "  if file_type == '2':\n",
        "    database_path = input(\"What is the path to your database? \")\n",
        "    table = input(\"What is the name of your table? \")\n",
        "    convert_json_to_sql(data, database_path, table)\n",
        "\n",
        "summarize_data(df)"
      ]
    }
  ]
}
