{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5gXV9JBDVJmWAPreMhDr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owen-shaffer/DataScience-Project/blob/main/DSSProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/owen-shaffer/DataScience-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yc5_l_Bbb7G",
        "outputId": "7be66bda-478a-4490-8ca7-44c39e343861"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DataScience-Project'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 36 (delta 11), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 2.40 MiB | 4.46 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF7h8jGIYIO6",
        "outputId": "ae685fe7-78b7-44ad-fc3f-7349eaa2fa00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide the path for your data: /content/DataScience-Project/AnimalDiversityNewYork.json\n",
            "\n",
            " Data Summary\n",
            "Number of rows: 1\n",
            "Number of columns: 78\n",
            "\n",
            "This is the first 5 rows of the data\n",
            "                                                data meta.view.id  \\\n",
            "0  [[row-gx47_u4gg-bdh6, 00000000-0000-0000-C362-...    tk82-7km5   \n",
            "\n",
            "                                      meta.view.name meta.view.assetType  \\\n",
            "0  Biodiversity by County - Distribution of Anima...             dataset   \n",
            "\n",
            "                               meta.view.attribution  \\\n",
            "0  New York State Department of Environmental Con...   \n",
            "\n",
            "                  meta.view.attributionLink  meta.view.averageRating  \\\n",
            "0  http://www.dec.ny.gov/animals/29338.html                        0   \n",
            "\n",
            "     meta.view.category  meta.view.createdAt  \\\n",
            "0  Energy & Environment           1405340161   \n",
            "\n",
            "                               meta.view.description  ...  \\\n",
            "0  The NYS Department of Environmental Conservati...  ...   \n",
            "\n",
            "  meta.view.tableAuthor.id  meta.view.tableAuthor.displayName  \\\n",
            "0                xzik-pf59                       NY Open Data   \n",
            "\n",
            "   meta.view.tableAuthor.profileImageUrlLarge  \\\n",
            "0   /api/users/xzik-pf59/profile_images/LARGE   \n",
            "\n",
            "   meta.view.tableAuthor.profileImageUrlMedium  \\\n",
            "0    /api/users/xzik-pf59/profile_images/THUMB   \n",
            "\n",
            "   meta.view.tableAuthor.profileImageUrlSmall  \\\n",
            "0    /api/users/xzik-pf59/profile_images/TINY   \n",
            "\n",
            "   meta.view.tableAuthor.screenName  meta.view.tableAuthor.type  \\\n",
            "0                      NY Open Data                 interactive   \n",
            "\n",
            "           meta.view.tableAuthor.flags  \\\n",
            "0  [acceptedEula, mayBeStoriesCoOwner]   \n",
            "\n",
            "                                      meta.view.tags  \\\n",
            "0  [biodiversity, endangered species, plants, ani...   \n",
            "\n",
            "                                     meta.view.flags  \n",
            "0  [default, ownerMayBeContacted, restorable, res...  \n",
            "\n",
            "[1 rows x 78 columns]\n",
            "\n",
            "\n",
            "Would you like to remove any columns? (y/n) n\n",
            "No columns removed\n",
            "\n",
            "\n",
            "Would you like to convert your data to csv (1), json(2), or sql (3)? 3\n",
            "What would you like to name your file? animalsNY\n",
            "\n",
            "Is your file a csv (1) or json (2)? 2\n",
            "\n",
            " Data Summary\n",
            "Number of rows: 1\n",
            "Number of columns: 78\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pandas import json_normalize\n",
        "import csv\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "#Functions\n",
        "#These functions take in two parameters, the data file and a name for the converted data file. The function opens the file and reads it into a\n",
        "#pandas dataframne. From there the data can be saved into the desired format.\n",
        "\n",
        "def convert_csv_to_json(csv_file, json_file):\n",
        "    with open(csv_file, 'r') as s:\n",
        "      df = pd.read_csv(s)\n",
        "      df.to_json(json_file, orient='records')\n",
        "\n",
        "def convert_json_to_csv(json_file, csv_file):\n",
        "  with open(data, 'r') as s:\n",
        "    json_data = json.load(s)\n",
        "    df = pd.json_normalize(json_data)\n",
        "    df.to_csv(csv_file)\n",
        "\n",
        "def convert_csv_to_sql(csv_file, sql_file):\n",
        "    with open(csv_file, 'r') as s:\n",
        "      df = pd.read_csv(s)\n",
        "      df.to_sql(sql_file, con=sqlite3.connect(sql_file))\n",
        "\n",
        "def convert_json_to_sql(json_file, sql_file):\n",
        "    with open(json_file, 'r') as s:\n",
        "      json_data = json.load(s)\n",
        "      df = pd.json_normalize(json_data)\n",
        "      for col in df.columns: #This code accounts for lists and dictioneries in the json data by turning them into strings. Without it the data cant be converted into a .db because sql only accepts basic text, int, float, null.\n",
        "      #The code iterates over each column and checks its type if it is an object so a list or dictionary then it goes through the conversion.\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = df[col].apply(lambda x: json.dumps(x) if isinstance(x, (dict, list)) else x)\n",
        "      df.to_sql(sql_file, con=sqlite3.connect(sql_file))\n",
        "\n",
        "def convert_sql(sql_file, new_file):\n",
        "  df = pd.read_sql(sql_file, con=sqlite3.connect(sql_file))\n",
        "  input = input(\"Would you like to convert your data to csv (1) or json(2)\")\n",
        "  if input == '1':\n",
        "    df.to_csv(new_file)\n",
        "  if input == '2':\n",
        "    df.to_json(new_file)\n",
        "  if input != '1' or '2':\n",
        "    print(\"Invalid input\")\n",
        "\n",
        "#This function takes in a dataframe and prints the number of rows and columns by taking the values from the .shape function output\n",
        "def summarize_data(df):\n",
        "    print(\"\\n Data Summary\")\n",
        "    print(f\"Number of rows: {df.shape[0]}\")\n",
        "    print(f\"Number of columns: {df.shape[1]}\")\n",
        "\n",
        "\n",
        "\n",
        "#Data ingesting and converting\n",
        "\n",
        "data = input(\"Provide the path for your data: \")\n",
        "\n",
        "#This chunk opens the data based on file type and turns it into a datafram\n",
        "if '.json' in data:\n",
        "  with open(data, 'r') as f:\n",
        "    json_data = json.load(f)\n",
        "    df = pd.json_normalize(json_data)# Within json data sometimes there are lists within dictionaries or vice versa. Pandas does not like turning this into a df so it needs to be 'flattened'. The normalize function converts this nested data into rows and columns\n",
        "if '.csv' in data:\n",
        "  df = pd.read_csv(data)\n",
        "if '.db' in data:\n",
        "  df = pd.read_sql(data, con=sqlite3.connect(data))\n",
        "\n",
        "summarize_data(df)\n",
        "\n",
        "print('')\n",
        "print('This is the first 5 rows of the data')\n",
        "print(df.head(), flush=True)\n",
        "\n",
        "print('')\n",
        "print('')\n",
        "\n",
        "remove = input(\"Would you like to remove any columns? (y/n) \")\n",
        "if remove == 'y':\n",
        "  print(\"What range of columns would you like to remove? \")\n",
        "  x_columns = input(\"Beginning at column: \")\n",
        "  y_columns = input(\"Ending at column: \")\n",
        "  if int(x_columns) > int(y_columns):\n",
        "    print(\"Invalid range\")\n",
        "  else:\n",
        "    df = df.drop(df.columns[int(x_columns):int(y_columns)], axis=1)\n",
        "    print(\"Columns removed\")\n",
        "    print(df.head())\n",
        "    print('')\n",
        "    print('')\n",
        "  if int(x_columns)>len(df.columns):\n",
        "    print(\"Invalid range\")\n",
        "  else:\n",
        "    print(\"Columns removed\")\n",
        "else:\n",
        "  print(\"No columns removed\")\n",
        "\n",
        "print('')\n",
        "print('')\n",
        "choice = input(\"Would you like to convert your data to csv (1), json(2), or sql (3)? \")\n",
        "name = input(\"What would you like to name your file? \")\n",
        "print('')\n",
        "\n",
        "if choice == '1':\n",
        "  if '.csv' in data:\n",
        "    print(\"Your file is already in csv format\")\n",
        "  else:\n",
        "    if '.json' in data:\n",
        "      convert_json_to_csv(data, name + '.csv')\n",
        "    if '.db' in data:\n",
        "      convert_sql(data, name + '.csv')\n",
        "\n",
        "if choice == '2':\n",
        "  if '.json' in data:\n",
        "    print(\"Your file is already in json format\")\n",
        "  else:\n",
        "    if '.db' in data:\n",
        "      convert_sql(data, name + '.json')\n",
        "    if '.csv' in data:\n",
        "      convert_csv_to_json(data, name + '.json')\n",
        "\n",
        "if choice == '3':\n",
        "  file_type = input(\"Is your file a csv (1) or json (2)? \")\n",
        "  if file_type == '1':\n",
        "    convert_csv_to_sql(data, name + '.db')\n",
        "  if file_type == '2':\n",
        "    convert_json_to_sql(data, name + '.db')\n",
        "\n",
        "summarize_data(df)"
      ]
    }
  ]
}